{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ee0b8-a95f-4482-8cbd-86ba0803c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "# 設定分界日\n",
    "split_date = \"2021-03-16\"\n",
    "\n",
    "def get_before_after_counts(file_path):\n",
    "    \"\"\"讀取檔案，切分 before/after，回傳 entity_type 統計\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # 切分\n",
    "    before_df = df[df['date'] < split_date]\n",
    "    after_df = df[df['date'] >= split_date]\n",
    "\n",
    "    # 過濾掉無效的 entity_type\n",
    "    exclude_types = ['Cannot be inferred', 'unknown', 'not applicable']\n",
    "    before_df = before_df[~before_df['entity_type'].isin(exclude_types)]\n",
    "    after_df = after_df[~after_df['entity_type'].isin(exclude_types)]\n",
    "\n",
    "    # 計算 counts\n",
    "    before_counts = before_df['entity_type'].value_counts()\n",
    "    after_counts = after_df['entity_type'].value_counts()\n",
    "\n",
    "    # 合併成 DataFrame\n",
    "    comparison = pd.DataFrame({\n",
    "        'Before': before_counts,\n",
    "        'After': after_counts\n",
    "    }).fillna(0).astype(int)\n",
    "\n",
    "    # 加上總和\n",
    "    comparison['Total'] = comparison['Before'] + comparison['After']\n",
    "\n",
    "    # 排序（依照 Total 由大到小）\n",
    "    comparison = comparison.sort_values(by='Total', ascending=False)\n",
    "\n",
    "    return comparison\n",
    "\n",
    "def chi_square_with_residuals(comparison_df):\n",
    "    \"\"\"卡方檢定 + 標準化殘差\"\"\"\n",
    "    contingency_table = comparison_df[['Before', 'After']].T.values\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    # 標準化殘差\n",
    "    residuals = (contingency_table - expected) / np.sqrt(expected)\n",
    "    residuals_df = pd.DataFrame(\n",
    "        residuals.T,\n",
    "        index=comparison_df.index,\n",
    "        columns=['Before_resid', 'After_resid']\n",
    "    )\n",
    "\n",
    "    return chi2, p, dof, residuals_df\n",
    "\n",
    "# 分別跑 step3 和 step4\n",
    "comparison_step3 = get_before_after_counts(\"step3_all_new.csv\")\n",
    "comparison_step4 = get_before_after_counts(\"step4_all_with_date.csv\")\n",
    "\n",
    "print(\"=== Step3 統計結果 ===\")\n",
    "print(comparison_step3)\n",
    "chi2, p, dof, residuals_df = chi_square_with_residuals(comparison_step3)\n",
    "print(f\"\\n[Step3] Chi-square = {chi2:.2f}, df = {dof}, p-value = {p:.4f}\")\n",
    "print(\"\\n[Step3] 標準化殘差：\")\n",
    "print(residuals_df)\n",
    "\n",
    "print(\"\\n=== Step4 統計結果 ===\")\n",
    "print(comparison_step4)\n",
    "chi2, p, dof, residuals_df = chi_square_with_residuals(comparison_step4)\n",
    "print(f\"\\n[Step4] Chi-square = {chi2:.2f}, df = {dof}, p-value = {p:.4f}\")\n",
    "print(\"\\n[Step4] 標準化殘差：\")\n",
    "print(residuals_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681fc50e-1caf-4102-9146-2d89d3f33726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. 讀取資料 ===\n",
    "df = pd.read_csv(\"step3_all_new.csv\")\n",
    "\n",
    "# 確認欄位名稱正確\n",
    "print(\"👉 欄位名稱：\", df.columns.tolist())\n",
    "\n",
    "# === 2. 日期轉換 ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# === 3. 設定分界日 ===\n",
    "cutoff_date = pd.to_datetime(\"2021-03-16\")\n",
    "\n",
    "before_df = df[df['date'] < cutoff_date]\n",
    "after_df = df[df['date'] >= cutoff_date]\n",
    "\n",
    "# === 4. 排除無效 reaction ===\n",
    "valid_reactions = ['Cannot be inferred', 'unknown']\n",
    "before_df_filtered = before_df[~before_df['reaction'].isin(valid_reactions)]\n",
    "after_df_filtered = after_df[~after_df['reaction'].isin(valid_reactions)]\n",
    "\n",
    "# === 5. 計算 reaction 出現次數 ===\n",
    "before_counts = before_df_filtered['reaction'].value_counts()\n",
    "after_counts = after_df_filtered['reaction'].value_counts()\n",
    "\n",
    "# === 6. 建立比較表 ===\n",
    "all_reactions = sorted(set(before_counts.index).union(set(after_counts.index)))\n",
    "reaction_comparison = pd.DataFrame(index=all_reactions)\n",
    "reaction_comparison['Before'] = before_counts\n",
    "reaction_comparison['After'] = after_counts\n",
    "reaction_comparison = reaction_comparison.fillna(0).astype(int)\n",
    "\n",
    "# === 7. 加入 Total 與百分比 ===\n",
    "reaction_comparison['Total'] = reaction_comparison['Before'] + reaction_comparison['After']\n",
    "\n",
    "total_before = reaction_comparison['Before'].sum()\n",
    "total_after = reaction_comparison['After'].sum()\n",
    "\n",
    "reaction_comparison['Before(%)'] = (reaction_comparison['Before'] / total_before * 100).round(2) if total_before > 0 else 0\n",
    "reaction_comparison['After(%)'] = (reaction_comparison['After'] / total_after * 100).round(2) if total_after > 0 else 0\n",
    "\n",
    "# === 8. 排序 ===\n",
    "reaction_comparison = reaction_comparison.sort_values(by='Total', ascending=False)\n",
    "\n",
    "# === 9. 輸出結果 ===\n",
    "pd.set_option(\"display.width\", 200)  # 預設 80\n",
    "pd.set_option(\"display.max_columns\", None)  # 顯示所有欄位\n",
    "pd.set_option(\"display.max_colwidth\", None)  # 不截斷文字\n",
    "print(\"📊 Reaction 數量與百分比比較：\")\n",
    "print(reaction_comparison)\n",
    "\n",
    "# 如果要存成 CSV\n",
    "# reaction_comparison.to_csv(\"reaction_comparison.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# === 10. Wilcoxon 檢定 ===\n",
    "before_vals = reaction_comparison[\"Before(%)\"]\n",
    "after_vals = reaction_comparison[\"After(%)\"]\n",
    "\n",
    "# 確保不是完全一樣的數據，否則 wilcoxon 會報錯\n",
    "if (before_vals != after_vals).any():\n",
    "    stat, p = wilcoxon(after_vals, before_vals)\n",
    "    print(\"\\n📊 Wilcoxon 符號等級檢定結果\")\n",
    "    print(\"Statistic =\", stat, \"  p-value =\", p)\n",
    "    if p < 0.05:\n",
    "        print(\"➡️ 結論：事件前後整體反應分布有顯著差異\")\n",
    "    else:\n",
    "        print(\"➡️ 結論：事件前後整體反應分布沒有顯著差異\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Before% 和 After% 完全相同，無法進行 Wilcoxon 檢定\")\n",
    "\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "# === 11. 卡方檢定 ===\n",
    "contingency_table = reaction_comparison[['Before', 'After']].T.values\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"\\n📊 卡方檢定結果\")\n",
    "print(f\"Chi-square = {chi2:.2f}, df = {dof}, p-value = {p:.4f}\")\n",
    "if p < 0.05:\n",
    "    print(\"➡️ 結論：事件前後反應分布有顯著差異\")\n",
    "else:\n",
    "    print(\"➡️ 結論：事件前後反應分布沒有顯著差異\")\n",
    "\n",
    "# === 12. 計算標準化殘差 ===\n",
    "residuals = (contingency_table - expected) / np.sqrt(expected)\n",
    "residuals_df = pd.DataFrame(\n",
    "    residuals.T,\n",
    "    index=reaction_comparison.index,\n",
    "    columns=['Before_resid', 'After_resid']\n",
    ")\n",
    "\n",
    "print(\"\\n📊 各反應類別的標準化殘差：\")\n",
    "print(residuals_df)\n",
    "\n",
    "# 如果要一起存成 CSV\n",
    "# result_with_resid = reaction_comparison.join(residuals_df)\n",
    "# result_with_resid.to_csv(\"reaction_comparison_with_resid.csv\", encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56d640-78e1-412f-bc93-238b5b29163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon, chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "# === 1. 讀取資料 ===\n",
    "df = pd.read_csv(\"step4_all_with_date.csv\")\n",
    "\n",
    "# 確認欄位\n",
    "print(\"👉 欄位名稱：\", df.columns.tolist())\n",
    "\n",
    "# === 2. 日期轉換 ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# === 3. 設定分界日 ===\n",
    "cutoff_date = pd.to_datetime(\"2021-03-16\")\n",
    "before_df = df[df['date'] < cutoff_date]\n",
    "after_df = df[df['date'] >= cutoff_date]\n",
    "\n",
    "# === 4. 排除無效 emotions ===\n",
    "valid_emotions = ['cannot be inferred', 'unknown']\n",
    "before_df_filtered = before_df[~before_df['emotion'].isin(valid_emotions)]\n",
    "after_df_filtered = after_df[~after_df['emotion'].isin(valid_emotions)]\n",
    "\n",
    "# === 5. 計算 emotion 出現次數 ===\n",
    "before_counts = before_df_filtered['emotion'].value_counts()\n",
    "after_counts = after_df_filtered['emotion'].value_counts()\n",
    "\n",
    "# === 6. 建立比較表 ===\n",
    "all_emotions = sorted(set(before_counts.index).union(set(after_counts.index)))\n",
    "emotion_comparison = pd.DataFrame(index=all_emotions)\n",
    "emotion_comparison['Before'] = before_counts\n",
    "emotion_comparison['After'] = after_counts\n",
    "emotion_comparison = emotion_comparison.fillna(0).astype(int)\n",
    "\n",
    "# === 7. 加入 Total 與百分比 ===\n",
    "emotion_comparison['Total'] = emotion_comparison['Before'] + emotion_comparison['After']\n",
    "\n",
    "total_before = emotion_comparison['Before'].sum()\n",
    "total_after = emotion_comparison['After'].sum()\n",
    "\n",
    "emotion_comparison['Before(%)'] = (emotion_comparison['Before'] / total_before * 100).round(2) if total_before > 0 else 0\n",
    "emotion_comparison['After(%)'] = (emotion_comparison['After'] / total_after * 100).round(2) if total_after > 0 else 0\n",
    "\n",
    "# === 8. 排序 ===\n",
    "emotion_comparison = emotion_comparison.sort_values(by='Total', ascending=False)\n",
    "\n",
    "# === 9. 顯示 ===\n",
    "pd.set_option(\"display.width\", 200)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "print(\"📊 Emotion 數量與百分比比較：\")\n",
    "print(emotion_comparison)\n",
    "\n",
    "# === 10. Wilcoxon 檢定 ===\n",
    "before_vals = emotion_comparison[\"Before(%)\"]\n",
    "after_vals = emotion_comparison[\"After(%)\"]\n",
    "\n",
    "if (before_vals != after_vals).any():\n",
    "    stat, p = wilcoxon(after_vals, before_vals)\n",
    "    print(\"\\n📊 Wilcoxon 符號等級檢定結果\")\n",
    "    print(\"Statistic =\", stat, \"  p-value =\", p)\n",
    "    if p < 0.05:\n",
    "        print(\"➡️ 結論：事件前後整體情緒分布有顯著差異\")\n",
    "    else:\n",
    "        print(\"➡️ 結論：事件前後整體情緒分布沒有顯著差異\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Before% 和 After% 完全相同，無法進行 Wilcoxon 檢定\")\n",
    "\n",
    "# === 11. 卡方檢定 ===\n",
    "contingency_table = emotion_comparison[['Before', 'After']].T.values\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"\\n📊 卡方檢定結果\")\n",
    "print(f\"Chi-square = {chi2:.2f}, df = {dof}, p-value = {p:.4f}\")\n",
    "if p < 0.05:\n",
    "    print(\"➡️ 結論：事件前後情緒分布有顯著差異\")\n",
    "else:\n",
    "    print(\"➡️ 結論：事件前後情緒分布沒有顯著差異\")\n",
    "\n",
    "# === 12. 標準化殘差 ===\n",
    "residuals = (contingency_table - expected) / np.sqrt(expected)\n",
    "residuals_df = pd.DataFrame(\n",
    "    residuals.T,\n",
    "    index=emotion_comparison.index,\n",
    "    columns=['Before_resid', 'After_resid']\n",
    ")\n",
    "\n",
    "# 也可以加上是否顯著標記\n",
    "residuals_df['Before_sig'] = residuals_df['Before_resid'].apply(lambda x: \"*\" if abs(x) > 2 else \"\")\n",
    "residuals_df['After_sig'] = residuals_df['After_resid'].apply(lambda x: \"*\" if abs(x) > 2 else \"\")\n",
    "\n",
    "print(\"\\n📊 各情緒類別的標準化殘差：\")\n",
    "print(residuals_df)\n",
    "\n",
    "# === 13. 合併輸出 (可存檔) ===\n",
    "# result_with_resid = emotion_comparison.join(residuals_df)\n",
    "# result_with_resid.to_csv(\"emotion_comparison_with_resid.csv\", encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092374c-2ebe-4647-ad4a-78993e212bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from scipy.stats import wilcoxon\n",
    "import numpy as np\n",
    "\n",
    "# === 1. 載入 CSV ===\n",
    "df = pd.read_csv(\"step3_all_new.csv\")\n",
    "\n",
    "# === 2. 日期轉換 & 切分 ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "cutoff_date = pd.to_datetime(\"2021-03-16\")\n",
    "\n",
    "before_df = df[df['date'] < cutoff_date].copy()\n",
    "after_df = df[df['date'] >= cutoff_date].copy()\n",
    "\n",
    "before_df['period'] = 'before'\n",
    "after_df['period'] = 'after'\n",
    "\n",
    "df = pd.concat([before_df, after_df], ignore_index=True)\n",
    "\n",
    "# === 3. 過濾無效值 ===\n",
    "invalid_reactions = ['Cannot be inferred', 'unknown', 'Cannot be inferred.']\n",
    "invalid_entity_types = ['Cannot be inferred', 'unknown']\n",
    "\n",
    "df = df[~df['reaction'].isin(invalid_reactions)]\n",
    "df = df[~df['entity_type'].isin(invalid_entity_types)]\n",
    "\n",
    "# === 4. 去重：同篇文章、同一個 entity、同一個 reaction 只保留一次 ===\n",
    "df_unique = df.drop_duplicates(subset=['article_id', 'entity', 'reaction'])\n",
    "\n",
    "# === 5. 準備所有 entity_type ===\n",
    "entity_types = sorted(df_unique['entity_type'].dropna().unique())\n",
    "\n",
    "all_rows = []\n",
    "for entity in entity_types:\n",
    "    be = df_unique[(df_unique['entity_type'] == entity) & (df_unique['period'] == 'before')]['reaction'].dropna().astype(str)\n",
    "    af = df_unique[(df_unique['entity_type'] == entity) & (df_unique['period'] == 'after')]['reaction'].dropna().astype(str)\n",
    "    \n",
    "    be_counts = Counter(be)\n",
    "    af_counts = Counter(af)\n",
    "    \n",
    "    all_reactions = sorted(set(be_counts.keys()) | set(af_counts.keys()))\n",
    "\n",
    "    total_be = sum(be_counts.values())\n",
    "    total_af = sum(af_counts.values())\n",
    "\n",
    "    for reaction in all_reactions:\n",
    "        be_n = be_counts.get(reaction, 0)\n",
    "        af_n = af_counts.get(reaction, 0)\n",
    "        row = {\n",
    "            'entity_type': entity,\n",
    "            'reaction': reaction,\n",
    "            'Before': be_n,\n",
    "            'After': af_n,\n",
    "            'Total': be_n + af_n,\n",
    "            'Before(%)': round(be_n / total_be * 100, 2) if total_be > 0 else 0,\n",
    "            'After(%)': round(af_n / total_af * 100, 2) if total_af > 0 else 0\n",
    "        }\n",
    "        all_rows.append(row)\n",
    "\n",
    "# === 6. 建立 DataFrame 並取前10名 ===\n",
    "comparison_df = pd.DataFrame(all_rows)\n",
    "comparison_df = comparison_df.sort_values(by=['entity_type', 'Total'], ascending=[True, False])\n",
    "top10_df = comparison_df.groupby('entity_type').head(10).reset_index(drop=True)\n",
    "\n",
    "# === 7. 各 entity_type 的 Wilcoxon 檢定 ===\n",
    "print(\"\\n📊 各 entity_type 的 Wilcoxon 檢定結果\")\n",
    "entity_results = []\n",
    "\n",
    "for entity in entity_types:\n",
    "    sub_df = comparison_df[comparison_df['entity_type'] == entity]\n",
    "    before_vals = sub_df[\"Before(%)\"]\n",
    "    after_vals = sub_df[\"After(%)\"]\n",
    "\n",
    "    # 避免全 0 或完全相同\n",
    "    if (before_vals != after_vals).any() and len(sub_df) > 0:\n",
    "        try:\n",
    "            stat, p = wilcoxon(after_vals, before_vals)\n",
    "            entity_results.append({\n",
    "                \"entity_type\": entity,\n",
    "                \"Statistic\": stat,\n",
    "                \"p-value\": p,\n",
    "                \"Significant\": \"Yes\" if p < 0.05 else \"No\"\n",
    "            })\n",
    "        except ValueError as e:\n",
    "            entity_results.append({\n",
    "                \"entity_type\": entity,\n",
    "                \"Statistic\": None,\n",
    "                \"p-value\": None,\n",
    "                \"Significant\": \"N/A\",\n",
    "                \"Note\": str(e)\n",
    "            })\n",
    "    else:\n",
    "        entity_results.append({\n",
    "            \"entity_type\": entity,\n",
    "            \"Statistic\": None,\n",
    "            \"p-value\": None,\n",
    "            \"Significant\": \"N/A\",\n",
    "            \"Note\": \"Before% 和 After% 完全相同或為空\"\n",
    "        })\n",
    "\n",
    "entity_results_df = pd.DataFrame(entity_results)\n",
    "print(entity_results_df)\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# === 卡方檢定：各 entity_type 的 Before vs After ===\n",
    "print(\"\\n📊 各 entity_type 的卡方檢定結果\")\n",
    "chi_results = []\n",
    "\n",
    "for entity in entity_types:\n",
    "    sub_df = comparison_df[comparison_df['entity_type'] == entity]\n",
    "\n",
    "    # 建立 反應 × 時間 的列聯表\n",
    "    contingency = sub_df[['Before','After']].to_numpy()\n",
    "\n",
    "    # 如果總數太小或只有一個反應，跳過\n",
    "    if contingency.shape[0] > 1 and contingency.sum() > 0:\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "        chi_results.append({\n",
    "            \"entity_type\": entity,\n",
    "            \"Chi2\": round(chi2, 3),\n",
    "            \"df\": dof,\n",
    "            \"p-value\": round(p, 4),\n",
    "            \"Significant\": \"Yes\" if p < 0.05 else \"No\"\n",
    "        })\n",
    "    else:\n",
    "        chi_results.append({\n",
    "            \"entity_type\": entity,\n",
    "            \"Chi2\": None,\n",
    "            \"df\": None,\n",
    "            \"p-value\": None,\n",
    "            \"Significant\": \"N/A\"\n",
    "        })\n",
    "\n",
    "chi_results_df = pd.DataFrame(chi_results)\n",
    "print(chi_results_df)\n",
    "\n",
    "print(\"\\n📊 顯著的 entity_type 的標準化殘差分析\")\n",
    "residuals_results = {}\n",
    "\n",
    "for entity in entity_types:\n",
    "    sub_df = comparison_df[comparison_df['entity_type'] == entity]\n",
    "    contingency = sub_df[['Before','After']].to_numpy()\n",
    "\n",
    "    if contingency.shape[0] > 1 and contingency.sum() > 0:\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "        if p < 0.05:  # 只針對顯著的群體\n",
    "            residuals = (contingency - expected) / np.sqrt(expected)\n",
    "\n",
    "            # 整理成 DataFrame\n",
    "            resid_df = pd.DataFrame(\n",
    "                residuals,\n",
    "                index=sub_df['reaction'],\n",
    "                columns=['Before_resid','After_resid']\n",
    "            ).round(2)\n",
    "\n",
    "            residuals_results[entity] = resid_df\n",
    "            print(f\"\\n🔎 {entity} 標準化殘差\")\n",
    "            print(resid_df)\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# === One-way ANOVA：各 entity_type Before% vs After% ===\n",
    "print(\"\\n📊 各 entity_type 的 One-way ANOVA 結果\")\n",
    "anova_results = []\n",
    "\n",
    "for entity in entity_types:\n",
    "    sub_df = comparison_df[comparison_df['entity_type'] == entity]\n",
    "\n",
    "    before_vals = sub_df[\"Before(%)\"].values\n",
    "    after_vals = sub_df[\"After(%)\"].values\n",
    "\n",
    "    # 確保不是空集合\n",
    "    if len(before_vals) > 0 and len(after_vals) > 0:\n",
    "        try:\n",
    "            f_stat, p_val = f_oneway(before_vals, after_vals)\n",
    "\n",
    "            # 判斷趨勢（看總和比較）\n",
    "            trend = \"Increase\" if after_vals.mean() > before_vals.mean() else \"Decrease\"\n",
    "\n",
    "            anova_results.append({\n",
    "                \"entity_type\": entity,\n",
    "                \"F-stat\": round(f_stat, 3),\n",
    "                \"p-value\": round(p_val, 4),\n",
    "                \"Significant\": \"Yes\" if p_val < 0.05 else \"No\",\n",
    "                \"Trend\": trend\n",
    "            })\n",
    "        except Exception as e:\n",
    "            anova_results.append({\n",
    "                \"entity_type\": entity,\n",
    "                \"F-stat\": None,\n",
    "                \"p-value\": None,\n",
    "                \"Significant\": \"N/A\",\n",
    "                \"Trend\": \"N/A\",\n",
    "                \"Note\": str(e)\n",
    "            })\n",
    "    else:\n",
    "        anova_results.append({\n",
    "            \"entity_type\": entity,\n",
    "            \"F-stat\": None,\n",
    "            \"p-value\": None,\n",
    "            \"Significant\": \"N/A\",\n",
    "            \"Trend\": \"N/A\",\n",
    "            \"Note\": \"Empty values\"\n",
    "        })\n",
    "\n",
    "anova_results_df = pd.DataFrame(anova_results)\n",
    "print(anova_results_df)\n",
    "\n",
    "\n",
    "\n",
    "# === 8. 顯示前十名 ===\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "\n",
    "print(\"\\n📊 各 entity_type 的前十名 Reaction 數量與百分比比較（事件前後，去重後）\")\n",
    "print(top10_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d3ebd-9ffa-4e83-9a9a-89341552d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# === 1. 假設 comparison_df 已經建好 ===\n",
    "df = comparison_df.copy()\n",
    "\n",
    "# === 2. 設定閾值，過小的 reaction 合併 ===\n",
    "threshold = 10\n",
    "df['reaction_merged'] = df.apply(\n",
    "    lambda row: row['reaction'] if row['Total'] >= threshold else \"Other reactions\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === 3. 重新彙總 ===\n",
    "merged = (\n",
    "    df.groupby(['entity_type','reaction_merged'])\n",
    "      .agg({'Before':'sum','After':'sum'})\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# 計算百分比\n",
    "results = []\n",
    "for entity, sub_df in merged.groupby('entity_type'):\n",
    "    total_be = sub_df['Before'].sum()\n",
    "    total_af = sub_df['After'].sum()\n",
    "    for _, row in sub_df.iterrows():\n",
    "        results.append({\n",
    "            'entity_type': entity,\n",
    "            'reaction': row['reaction_merged'],\n",
    "            'Before': row['Before'],\n",
    "            'After': row['After'],\n",
    "            'Total': row['Before'] + row['After'],\n",
    "            'Before(%)': round(row['Before'] / total_be * 100, 2) if total_be > 0 else 0,\n",
    "            'After(%)': round(row['After'] / total_af * 100, 2) if total_af > 0 else 0\n",
    "        })\n",
    "\n",
    "merged_df = pd.DataFrame(results)\n",
    "\n",
    "# === 4. 各 entity_type 的 Wilcoxon 檢定 ===\n",
    "wilcoxon_results = []\n",
    "for entity, sub_df in merged_df.groupby('entity_type'):\n",
    "    before_vals = sub_df['Before(%)']\n",
    "    after_vals = sub_df['After(%)']\n",
    "    if (before_vals != after_vals).any() and len(sub_df) > 1:\n",
    "        try:\n",
    "            stat, p = wilcoxon(after_vals, before_vals)\n",
    "            wilcoxon_results.append({\n",
    "                \"entity_type\": entity,\n",
    "                \"Statistic\": stat,\n",
    "                \"p-value\": p,\n",
    "                \"Significant\": \"Yes\" if p < 0.05 else \"No\"\n",
    "            })\n",
    "        except ValueError as e:\n",
    "            wilcoxon_results.append({\n",
    "                \"entity_type\": entity,\n",
    "                \"Statistic\": None,\n",
    "                \"p-value\": None,\n",
    "                \"Significant\": \"N/A\",\n",
    "                \"Note\": str(e)\n",
    "            })\n",
    "\n",
    "wilcoxon_df = pd.DataFrame(wilcoxon_results)\n",
    "print(\"\\n📊 各 entity_type 的 Wilcoxon 檢定結果（合併低頻反應後）\")\n",
    "print(wilcoxon_df)\n",
    "\n",
    "print(\"\\n📊 各 entity_type 的卡方檢定結果（合併低頻反應後）\")\n",
    "chi_results = []\n",
    "\n",
    "for entity, sub_df in merged_df.groupby('entity_type'):\n",
    "    contingency = sub_df[['Before','After']].to_numpy()\n",
    "\n",
    "    if contingency.shape[0] > 1 and contingency.sum() > 0:\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "        chi_results.append({\n",
    "            \"entity_type\": entity,\n",
    "            \"Chi2\": round(chi2, 3),\n",
    "            \"df\": dof,\n",
    "            \"p-value\": round(p, 4),\n",
    "            \"Significant\": \"Yes\" if p < 0.05 else \"No\"\n",
    "        })\n",
    "    else:\n",
    "        chi_results.append({\n",
    "            \"entity_type\": entity,\n",
    "            \"Chi2\": None,\n",
    "            \"df\": None,\n",
    "            \"p-value\": None,\n",
    "            \"Significant\": \"N/A\"\n",
    "        })\n",
    "\n",
    "chi_results_df = pd.DataFrame(chi_results)\n",
    "print(chi_results_df)\n",
    "\n",
    "\n",
    "# === 6. 顯示合併後的反應總表（前十名）===\n",
    "merged_df = merged_df.sort_values(by=['entity_type', 'Total'], ascending=[True, False])\n",
    "top10_merged = merged_df.groupby('entity_type').head(10).reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "\n",
    "print(\"\\n📊 各 entity_type 的前十名 Reaction 數量與百分比比較（事件前後，合併低頻後）\")\n",
    "print(top10_merged)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5447b151-9e1a-4a23-b39d-793de8540784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. 載入 CSV ===\n",
    "df = pd.read_csv(\"step4_all_with_date.csv\")\n",
    "\n",
    "# === 2. 日期轉換 & 切分 ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "cutoff_date = pd.to_datetime(\"2021-03-16\")\n",
    "\n",
    "before_df = df[df['date'] < cutoff_date].copy()\n",
    "after_df = df[df['date'] >= cutoff_date].copy()\n",
    "\n",
    "# === 3. 排除無效 emotion 值的 row ===\n",
    "invalid_emotions = ['cannot be inferred', 'unknown']\n",
    "valid_before = before_df[~before_df['emotion'].isin(invalid_emotions)]\n",
    "valid_after = after_df[~after_df['emotion'].isin(invalid_emotions)]\n",
    "\n",
    "# === 4. 排除無效 entity_type 的 row ===\n",
    "invalid_entity_types = ['Cannot be inferred', 'unknown']\n",
    "valid_before = valid_before[~valid_before['entity_type'].isin(invalid_entity_types)]\n",
    "valid_after = valid_after[~valid_after['entity_type'].isin(invalid_entity_types)]\n",
    "\n",
    "# === 5. 找出所有出現過的 entity_type ===\n",
    "entity_types = sorted(set(valid_before['entity_type'].dropna()) | set(valid_after['entity_type'].dropna()))\n",
    "\n",
    "# === 6. 統計每個 entity_type 的 emotion ===\n",
    "all_rows = []\n",
    "\n",
    "def extract_emotions(series):\n",
    "    all_emotions = []\n",
    "    for item in series.dropna():\n",
    "        parts = [e.strip() for e in item.split('|') if e.strip() and e.strip() not in invalid_emotions]\n",
    "        all_emotions.extend(parts)\n",
    "    return Counter(all_emotions)\n",
    "\n",
    "for entity in entity_types:\n",
    "    be_series = valid_before[valid_before['entity_type'] == entity]['emotion']\n",
    "    af_series = valid_after[valid_after['entity_type'] == entity]['emotion']\n",
    "\n",
    "    be_counts = extract_emotions(be_series)\n",
    "    af_counts = extract_emotions(af_series)\n",
    "\n",
    "    all_emotions = sorted(set(be_counts.keys()) | set(af_counts.keys()))\n",
    "    total_be = sum(be_counts.values())\n",
    "    total_af = sum(af_counts.values())\n",
    "\n",
    "    for emotion in all_emotions:\n",
    "        be_n = be_counts.get(emotion, 0)\n",
    "        af_n = af_counts.get(emotion, 0)\n",
    "        row = {\n",
    "            'entity_type': entity,\n",
    "            'emotion': emotion,\n",
    "            'Before': be_n,\n",
    "            'After': af_n,\n",
    "            'Total': be_n + af_n,\n",
    "            'Before(%)': round(be_n / total_be * 100, 2) if total_be > 0 else 0,\n",
    "            'After(%)': round(af_n / total_af * 100, 2) if total_af > 0 else 0\n",
    "        }\n",
    "        all_rows.append(row)\n",
    "\n",
    "# === 7. 建立 DataFrame 並取每個 entity_type 的前10個情緒 ===\n",
    "comparison_df = pd.DataFrame(all_rows)\n",
    "comparison_df = comparison_df.sort_values(by=['entity_type', 'Total'], ascending=[True, False])\n",
    "top10_df = comparison_df.groupby('entity_type').head(10).reset_index(drop=True)\n",
    "\n",
    "# === 8. 顯示設定 ===\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.colheader_justify', 'left')\n",
    "\n",
    "# === 9. 顯示結果 ===\n",
    "print(\"📊 各 entity_type 的前十名 Emotion 數量與百分比比較（事件前後）\")\n",
    "print(top10_df)\n",
    "\n",
    "# ✅（可選）輸出成 CSV\n",
    "# top10_df.to_csv(\"step4_top10_entity_emotions.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a71717-28a0-44f2-a129-8d9ddc7477dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# === 1. 載入資料 ===\n",
    "df = pd.read_csv(\"step3_all_with_date.csv\")\n",
    "\n",
    "# === 2. 日期切分 ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "cutoff_date = pd.to_datetime(\"2021-03-16\")\n",
    "\n",
    "before_df = df[df['date'] < cutoff_date].copy()\n",
    "after_df = df[df['date'] >= cutoff_date].copy()\n",
    "\n",
    "# === 3. 分類成 individual / organization ===\n",
    "def classify_entity_group(e):\n",
    "    if e in ['victims', 'other_individuals', 'professionals', 'politicians', 'perpetrators', 'celebrities']:\n",
    "        return 'individual'\n",
    "    elif e in ['ngo_or_advocacy_groups', 'law_enforcement_agencies', 'community_groups',\n",
    "               'government_bodies', 'business_entities']:\n",
    "        return 'organization'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "before_df['entity_group'] = before_df['entity_type'].apply(classify_entity_group)\n",
    "after_df['entity_group'] = after_df['entity_type'].apply(classify_entity_group)\n",
    "\n",
    "# === 4. 過濾無效值 ===\n",
    "invalid_reactions = ['Cannot be inferred', 'unknown']\n",
    "valid_before = before_df[\n",
    "    (~before_df['reaction'].isin(invalid_reactions)) &\n",
    "    (before_df['entity_group'].isin(['individual', 'organization']))\n",
    "]\n",
    "valid_after = after_df[\n",
    "    (~after_df['reaction'].isin(invalid_reactions)) &\n",
    "    (after_df['entity_group'].isin(['individual', 'organization']))\n",
    "]\n",
    "\n",
    "# === 5. 統計各 group 的 reaction ===\n",
    "all_rows = []\n",
    "\n",
    "for group in ['individual', 'organization']:\n",
    "    be = valid_before[valid_before['entity_group'] == group]['reaction'].dropna().astype(str)\n",
    "    af = valid_after[valid_after['entity_group'] == group]['reaction'].dropna().astype(str)\n",
    "\n",
    "    be_counts = Counter(be)\n",
    "    af_counts = Counter(af)\n",
    "\n",
    "    all_reactions = sorted(set(be_counts.keys()) | set(af_counts.keys()))\n",
    "    total_be = sum(be_counts.values())\n",
    "    total_af = sum(af_counts.values())\n",
    "\n",
    "    for reaction in all_reactions:\n",
    "        be_n = be_counts.get(reaction, 0)\n",
    "        af_n = af_counts.get(reaction, 0)\n",
    "        row = {\n",
    "            'entity_group': group,\n",
    "            'reaction': reaction,\n",
    "            'Before': be_n,\n",
    "            'After': af_n,\n",
    "            'Total': be_n + af_n,\n",
    "            'Before(%)': round(be_n / total_be * 100, 2) if total_be > 0 else 0,\n",
    "            'After(%)': round(af_n / total_af * 100, 2) if total_af > 0 else 0,\n",
    "        }\n",
    "        all_rows.append(row)\n",
    "\n",
    "# === 6. 整理結果 ===\n",
    "reaction_comparison_df = pd.DataFrame(all_rows)\n",
    "reaction_comparison_df = reaction_comparison_df.sort_values(by=['entity_group', 'Total'], ascending=[True, False])\n",
    "\n",
    "# === 7. 只取各 group 前 20 ===\n",
    "top20_reaction_df = reaction_comparison_df.groupby('entity_group').head(20).reset_index(drop=True)\n",
    "\n",
    "# === 8. 顯示 ===\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.colheader_justify', 'left')\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"📊 個人 vs 組織的 Reaction 前 20 名 數量與百分比比較：\")\n",
    "print(top20_reaction_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82417193-14f1-4408-846d-f51ffd755620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# === 1. 讀取資料 ===\n",
    "df = pd.read_csv(\"step4_all_with_date.csv\")\n",
    "\n",
    "# === 2. 日期切分 ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "cutoff_date = pd.to_datetime(\"2021-03-16\")\n",
    "\n",
    "before_df = df[df['date'] < cutoff_date].copy()\n",
    "after_df = df[df['date'] >= cutoff_date].copy()\n",
    "\n",
    "# === 3. 分類 entity_group ===\n",
    "def classify_entity_group(e):\n",
    "    if e in ['victims', 'other_individuals', 'professionals', 'politicians', 'perpetrators', 'celebrities']:\n",
    "        return 'individual'\n",
    "    elif e in ['ngo_or_advocacy_groups', 'law_enforcement_agencies', 'community_groups',\n",
    "               'government_bodies', 'business_entities']:\n",
    "        return 'organization'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "before_df['entity_group'] = before_df['entity_type'].apply(classify_entity_group)\n",
    "after_df['entity_group'] = after_df['entity_type'].apply(classify_entity_group)\n",
    "\n",
    "# === 4. 過濾 valid rows (排除無效情緒 & 只取 individual / organization) ===\n",
    "invalid_emotions = ['cannot be inferred', 'unknown']\n",
    "\n",
    "valid_before = before_df[\n",
    "    (before_df['entity_group'].isin(['individual', 'organization'])) &\n",
    "    (before_df['emotion'].notna())\n",
    "]\n",
    "valid_after = after_df[\n",
    "    (after_df['entity_group'].isin(['individual', 'organization'])) &\n",
    "    (after_df['emotion'].notna())\n",
    "]\n",
    "\n",
    "# === 5. 處理多個 emotion 的欄位 ===\n",
    "def extract_emotions(series):\n",
    "    all_emotions = []\n",
    "    for item in series.dropna():\n",
    "        parts = [e.strip().lower() for e in item.split('|') if e.strip().lower() not in invalid_emotions]\n",
    "        all_emotions.extend(parts)\n",
    "    return Counter(all_emotions)\n",
    "\n",
    "# === 6. 統計每個 entity_group 的情緒 ===\n",
    "all_rows = []\n",
    "\n",
    "for group in ['individual', 'organization']:\n",
    "    be_series = valid_before[valid_before['entity_group'] == group]['emotion']\n",
    "    af_series = valid_after[valid_after['entity_group'] == group]['emotion']\n",
    "\n",
    "    be_counts = extract_emotions(be_series)\n",
    "    af_counts = extract_emotions(af_series)\n",
    "\n",
    "    all_emotions = sorted(set(be_counts.keys()) | set(af_counts.keys()))\n",
    "    total_be = sum(be_counts.values())\n",
    "    total_af = sum(af_counts.values())\n",
    "\n",
    "    for emotion in all_emotions:\n",
    "        be_n = be_counts.get(emotion, 0)\n",
    "        af_n = af_counts.get(emotion, 0)\n",
    "        row = {\n",
    "            'entity_group': group,\n",
    "            'emotion': emotion,\n",
    "            'Before': be_n,\n",
    "            'After': af_n,\n",
    "            'Total': be_n + af_n,\n",
    "            'Before(%)': round(be_n / total_be * 100, 2) if total_be > 0 else 0,\n",
    "            'After(%)': round(af_n / total_af * 100, 2) if total_af > 0 else 0,\n",
    "        }\n",
    "        all_rows.append(row)\n",
    "\n",
    "# === 7. 建立 DataFrame 並排序 ===\n",
    "emotion_comparison_df = pd.DataFrame(all_rows)\n",
    "emotion_comparison_df = emotion_comparison_df.sort_values(by=['entity_group', 'Total'], ascending=[True, False])\n",
    "\n",
    "# === 8. 只取前 20 個 emotion ===\n",
    "top20_emotion_df = emotion_comparison_df.groupby('entity_group').head(20).reset_index(drop=True)\n",
    "\n",
    "# === 9. 顯示設定 ===\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.colheader_justify', 'left')\n",
    "\n",
    "# === 10. 顯示結果 ===\n",
    "print(\"📊 個人 vs 組織的 Emotion 前 20 名 數量與百分比比較：\")\n",
    "print(top20_emotion_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
