{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8113c586-beff-4c71-92e8-2ff96fd7ca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘‰ æ¬„ä½åç¨±ï¼š ['emotion_id', 'article_id', 'entity', 'entity_type', 'asian_status', 'emotion', 'emotion_reason', 'date']\n",
      "ğŸ“Š Emotion æ•¸é‡èˆ‡ç™¾åˆ†æ¯”æ¯”è¼ƒï¼š\n",
      "          Before  After  Total  Before(%)  After(%)\n",
      "sadness      857   1038   1895      31.37     37.37\n",
      "anger        925    864   1789      33.86     31.10\n",
      "fear         709    668   1377      25.95     24.05\n",
      "joy          125     93    218       4.58      3.35\n",
      "love          83     85    168       3.04      3.06\n",
      "surprise      33     30     63       1.21      1.08\n",
      "Empty DataFrame\n",
      "Columns: [emotion_id, article_id, entity, entity_type, asian_status, emotion, emotion_reason, date]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. è®€å–è³‡æ–™ ===\n",
    "df = pd.read_csv(\"step4_all_with_date.csv\")\n",
    "\n",
    "# ç¢ºèªæ¬„ä½\n",
    "print(\"ğŸ‘‰ æ¬„ä½åç¨±ï¼š\", df.columns.tolist())\n",
    "\n",
    "# === 2. æ—¥æœŸè½‰æ› ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# === 3. è¨­å®šåˆ†ç•Œæ—¥ ===\n",
    "cutoff_date = pd.to_datetime(\"2021-03-16\")\n",
    "before_df = df[df['date'] < cutoff_date]\n",
    "after_df = df[df['date'] >= cutoff_date]\n",
    "\n",
    "# === 4. æ’é™¤ç„¡æ•ˆ emotions ===\n",
    "valid_emotions = ['cannot be inferred', 'unknown']\n",
    "before_df_filtered = before_df[~before_df['emotion'].isin(valid_emotions)]\n",
    "after_df_filtered = after_df[~after_df['emotion'].isin(valid_emotions)]\n",
    "\n",
    "# === 5. è¨ˆç®— emotion å‡ºç¾æ¬¡æ•¸ ===\n",
    "before_counts = before_df_filtered['emotion'].value_counts()\n",
    "after_counts = after_df_filtered['emotion'].value_counts()\n",
    "\n",
    "# === 6. å»ºç«‹æ¯”è¼ƒè¡¨ ===\n",
    "all_emotions = sorted(set(before_counts.index).union(set(after_counts.index)))\n",
    "emotion_comparison = pd.DataFrame(index=all_emotions)\n",
    "emotion_comparison['Before'] = before_counts\n",
    "emotion_comparison['After'] = after_counts\n",
    "emotion_comparison = emotion_comparison.fillna(0).astype(int)\n",
    "\n",
    "# === 7. åŠ å…¥ Total èˆ‡ç™¾åˆ†æ¯” ===\n",
    "emotion_comparison['Total'] = emotion_comparison['Before'] + emotion_comparison['After']\n",
    "\n",
    "total_before = emotion_comparison['Before'].sum()\n",
    "total_after = emotion_comparison['After'].sum()\n",
    "\n",
    "emotion_comparison['Before(%)'] = (emotion_comparison['Before'] / total_before * 100).round(2) if total_before > 0 else 0\n",
    "emotion_comparison['After(%)'] = (emotion_comparison['After'] / total_after * 100).round(2) if total_after > 0 else 0\n",
    "\n",
    "# === 8. æ’åº ===\n",
    "emotion_comparison = emotion_comparison.sort_values(by='Total', ascending=False)\n",
    "\n",
    "# === 9. é¡¯ç¤º ===\n",
    "print(\"ğŸ“Š Emotion æ•¸é‡èˆ‡ç™¾åˆ†æ¯”æ¯”è¼ƒï¼š\")\n",
    "print(emotion_comparison)\n",
    "\n",
    "# # === 10. å­˜æˆ CSV (å¯é¸) ===\n",
    "# emotion_comparison.to_csv(\"emotion_comparison.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "compassion_rows = df[df[\"emotion\"].str.contains(\"solidarity\", case=False, na=False)]\n",
    "\n",
    "# é¡¯ç¤ºçµæœ\n",
    "print(compassion_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f72cac-82e0-4f3a-b74d-bfc4681cb493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š å„ entity_type çš„å‰åå Emotion æ•¸é‡èˆ‡ç™¾åˆ†æ¯”æ¯”è¼ƒï¼ˆäº‹ä»¶å‰å¾Œï¼‰\n",
      "   entity_type               emotion    Before  After  Total  Before(%)  After(%)\n",
      "0          business_entities   sadness    9       2     11    60.00      18.18   \n",
      "1          business_entities     anger    2       6      8    13.33      54.55   \n",
      "2          business_entities      fear    4       2      6    26.67      18.18   \n",
      "3          business_entities      love    0       1      1     0.00       9.09   \n",
      "4                celebrities     anger   38      19     57    39.18      28.79   \n",
      "5                celebrities   sadness   26      26     52    26.80      39.39   \n",
      "6                celebrities      fear   19      10     29    19.59      15.15   \n",
      "7                celebrities       joy    5       6     11     5.15       9.09   \n",
      "8                celebrities      love    4       4      8     4.12       6.06   \n",
      "9                celebrities  surprise    5       1      6     5.15       1.52   \n",
      "10          community_groups     anger    8       8     16    42.11      50.00   \n",
      "11          community_groups   sadness    5       5     10    26.32      31.25   \n",
      "12          community_groups      fear    5       1      6    26.32       6.25   \n",
      "13          community_groups       joy    1       1      2     5.26       6.25   \n",
      "14          community_groups      love    0       1      1     0.00       6.25   \n",
      "15         government_bodies     anger   14       3     17    38.89      20.00   \n",
      "16         government_bodies      fear    9       3     12    25.00      20.00   \n",
      "17         government_bodies   sadness    7       3     10    19.44      20.00   \n",
      "18         government_bodies      love    2       5      7     5.56      33.33   \n",
      "19         government_bodies       joy    3       1      4     8.33       6.67   \n",
      "20         government_bodies  surprise    1       0      1     2.78       0.00   \n",
      "21  law_enforcement_agencies      fear   20       8     28    50.00      24.24   \n",
      "22  law_enforcement_agencies     anger   10      16     26    25.00      48.48   \n",
      "23  law_enforcement_agencies   sadness    7       4     11    17.50      12.12   \n",
      "24  law_enforcement_agencies  surprise    3       3      6     7.50       9.09   \n",
      "25  law_enforcement_agencies      love    0       2      2     0.00       6.06   \n",
      "26    ngo_or_advocacy_groups     anger   65      62    127    40.62      33.51   \n",
      "27    ngo_or_advocacy_groups   sadness   49      72    121    30.63      38.92   \n",
      "28    ngo_or_advocacy_groups      fear   31      39     70    19.38      21.08   \n",
      "29    ngo_or_advocacy_groups       joy   11       5     16     6.88       2.70   \n",
      "30    ngo_or_advocacy_groups      love    4       5      9     2.50       2.70   \n",
      "31    ngo_or_advocacy_groups  surprise    0       2      2     0.00       1.08   \n",
      "32            not applicable      fear    0       2      2     0.00      66.67   \n",
      "33            not applicable   sadness    0       1      1     0.00      33.33   \n",
      "34         other_individuals   sadness  112     168    280    29.32      33.60   \n",
      "35         other_individuals      fear  101     149    250    26.44      29.80   \n",
      "36         other_individuals     anger   93     135    228    24.35      27.00   \n",
      "37         other_individuals       joy   41      30     71    10.73       6.00   \n",
      "38         other_individuals      love   24      12     36     6.28       2.40   \n",
      "39         other_individuals  surprise   11       6     17     2.88       1.20   \n",
      "40              perpetrators     anger   82      83    165    94.25      88.30   \n",
      "41              perpetrators      fear    2       9     11     2.30       9.57   \n",
      "42              perpetrators  surprise    2       2      4     2.30       2.13   \n",
      "43              perpetrators   sadness    1       0      1     1.15       0.00   \n",
      "44               politicians     anger  274     208    482    63.57      54.59   \n",
      "45               politicians   sadness   69      84    153    16.01      22.05   \n",
      "46               politicians      fear   51      56    107    11.83      14.70   \n",
      "47               politicians      love   20      21     41     4.64       5.51   \n",
      "48               politicians       joy   15      12     27     3.48       3.15   \n",
      "49               politicians  surprise    2       0      2     0.46       0.00   \n",
      "50             professionals   sadness  213     227    440    34.41      38.41   \n",
      "51             professionals     anger  180     164    344    29.08      27.75   \n",
      "52             professionals      fear  168     147    315    27.14      24.87   \n",
      "53             professionals       joy   35      19     54     5.65       3.21   \n",
      "54             professionals      love   16      21     37     2.58       3.55   \n",
      "55             professionals  surprise    7      13     20     1.13       2.20   \n",
      "56                   victims   sadness  359     445    804    42.54      50.68   \n",
      "57                   victims      fear  298     241    539    35.31      27.45   \n",
      "58                   victims     anger  159     158    317    18.84      18.00   \n",
      "59                   victims       joy   13      19     32     1.54       2.16   \n",
      "60                   victims      love   13      12     25     1.54       1.37   \n",
      "61                   victims  surprise    2       3      5     0.24       0.34   \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. è¼‰å…¥ CSV ===\n",
    "df = pd.read_csv(\"step4_all_with_date.csv\")\n",
    "\n",
    "# === 2. æ—¥æœŸè½‰æ› & åˆ‡åˆ† ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "cutoff_date = pd.to_datetime(\"2021-03-16\")\n",
    "\n",
    "before_df = df[df['date'] < cutoff_date].copy()\n",
    "after_df = df[df['date'] >= cutoff_date].copy()\n",
    "\n",
    "# === 3. æ’é™¤ç„¡æ•ˆ emotion å€¼çš„ row ===\n",
    "invalid_emotions = ['cannot be inferred', 'unknown']\n",
    "valid_before = before_df[~before_df['emotion'].isin(invalid_emotions)]\n",
    "valid_after = after_df[~after_df['emotion'].isin(invalid_emotions)]\n",
    "\n",
    "# === 4. æ’é™¤ç„¡æ•ˆ entity_type çš„ row ===\n",
    "invalid_entity_types = ['Cannot be inferred', 'unknown']\n",
    "valid_before = valid_before[~valid_before['entity_type'].isin(invalid_entity_types)]\n",
    "valid_after = valid_after[~valid_after['entity_type'].isin(invalid_entity_types)]\n",
    "\n",
    "# === 5. æ‰¾å‡ºæ‰€æœ‰å‡ºç¾éçš„ entity_type ===\n",
    "entity_types = sorted(set(valid_before['entity_type'].dropna()) | set(valid_after['entity_type'].dropna()))\n",
    "\n",
    "# === 6. çµ±è¨ˆæ¯å€‹ entity_type çš„ emotion ===\n",
    "all_rows = []\n",
    "\n",
    "def extract_emotions(series):\n",
    "    all_emotions = []\n",
    "    for item in series.dropna():\n",
    "        parts = [e.strip() for e in item.split('|') if e.strip() and e.strip() not in invalid_emotions]\n",
    "        all_emotions.extend(parts)\n",
    "    return Counter(all_emotions)\n",
    "\n",
    "for entity in entity_types:\n",
    "    be_series = valid_before[valid_before['entity_type'] == entity]['emotion']\n",
    "    af_series = valid_after[valid_after['entity_type'] == entity]['emotion']\n",
    "\n",
    "    be_counts = extract_emotions(be_series)\n",
    "    af_counts = extract_emotions(af_series)\n",
    "\n",
    "    all_emotions = sorted(set(be_counts.keys()) | set(af_counts.keys()))\n",
    "    total_be = sum(be_counts.values())\n",
    "    total_af = sum(af_counts.values())\n",
    "\n",
    "    for emotion in all_emotions:\n",
    "        be_n = be_counts.get(emotion, 0)\n",
    "        af_n = af_counts.get(emotion, 0)\n",
    "        row = {\n",
    "            'entity_type': entity,\n",
    "            'emotion': emotion,\n",
    "            'Before': be_n,\n",
    "            'After': af_n,\n",
    "            'Total': be_n + af_n,\n",
    "            'Before(%)': round(be_n / total_be * 100, 2) if total_be > 0 else 0,\n",
    "            'After(%)': round(af_n / total_af * 100, 2) if total_af > 0 else 0\n",
    "        }\n",
    "        all_rows.append(row)\n",
    "\n",
    "# === 7. å»ºç«‹ DataFrame ä¸¦å–æ¯å€‹ entity_type çš„å‰10å€‹æƒ…ç·’ ===\n",
    "comparison_df = pd.DataFrame(all_rows)\n",
    "comparison_df = comparison_df.sort_values(by=['entity_type', 'Total'], ascending=[True, False])\n",
    "top10_df = comparison_df.groupby('entity_type').head(10).reset_index(drop=True)\n",
    "\n",
    "# === 8. é¡¯ç¤ºè¨­å®š ===\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.colheader_justify', 'left')\n",
    "\n",
    "# === 9. é¡¯ç¤ºçµæœ ===\n",
    "print(\"ğŸ“Š å„ entity_type çš„å‰åå Emotion æ•¸é‡èˆ‡ç™¾åˆ†æ¯”æ¯”è¼ƒï¼ˆäº‹ä»¶å‰å¾Œï¼‰\")\n",
    "print(top10_df)\n",
    "\n",
    "# âœ…ï¼ˆå¯é¸ï¼‰è¼¸å‡ºæˆ CSV\n",
    "# top10_df.to_csv(\"step4_top10_entity_emotions.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0fe4825-56a7-4fff-b0a2-4a5418fae518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š å€‹äºº vs çµ„ç¹”çš„ Emotion å‰ 20 å æ•¸é‡èˆ‡ç™¾åˆ†æ¯”æ¯”è¼ƒï¼š\n",
      "   entity_group  emotion    Before  After  Total  Before(%)  After(%)\n",
      "0     individual   sadness  780     950    1730   31.71      37.85   \n",
      "1     individual     anger  826     767    1593   33.58      30.56   \n",
      "2     individual      fear  639     612    1251   25.98      24.38   \n",
      "3     individual       joy  109      86     195    4.43       3.43   \n",
      "4     individual      love   77      70     147    3.13       2.79   \n",
      "5     individual  surprise   29      25      54    1.18       1.00   \n",
      "6   organization     anger   99      95     194   36.67      36.54   \n",
      "7   organization   sadness   77      86     163   28.52      33.08   \n",
      "8   organization      fear   69      53     122   25.56      20.38   \n",
      "9   organization       joy   15       7      22    5.56       2.69   \n",
      "10  organization      love    6      14      20    2.22       5.38   \n",
      "11  organization  surprise    4       5       9    1.48       1.92   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# === 1. è®€å–è³‡æ–™ ===\n",
    "df = pd.read_csv(\"step4_all_with_date.csv\")\n",
    "\n",
    "# === 2. æ—¥æœŸåˆ‡åˆ† ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "cutoff_date = pd.to_datetime(\"2021-03-16\")\n",
    "\n",
    "before_df = df[df['date'] < cutoff_date].copy()\n",
    "after_df = df[df['date'] >= cutoff_date].copy()\n",
    "\n",
    "# === 3. åˆ†é¡ entity_group ===\n",
    "def classify_entity_group(e):\n",
    "    if e in ['victims', 'other_individuals', 'professionals', 'politicians', 'perpetrators', 'celebrities']:\n",
    "        return 'individual'\n",
    "    elif e in ['ngo_or_advocacy_groups', 'law_enforcement_agencies', 'community_groups',\n",
    "               'government_bodies', 'business_entities']:\n",
    "        return 'organization'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "before_df['entity_group'] = before_df['entity_type'].apply(classify_entity_group)\n",
    "after_df['entity_group'] = after_df['entity_type'].apply(classify_entity_group)\n",
    "\n",
    "# === 4. éæ¿¾ valid rows (æ’é™¤ç„¡æ•ˆæƒ…ç·’ & åªå– individual / organization) ===\n",
    "invalid_emotions = ['cannot be inferred', 'unknown']\n",
    "\n",
    "valid_before = before_df[\n",
    "    (before_df['entity_group'].isin(['individual', 'organization'])) &\n",
    "    (before_df['emotion'].notna())\n",
    "]\n",
    "valid_after = after_df[\n",
    "    (after_df['entity_group'].isin(['individual', 'organization'])) &\n",
    "    (after_df['emotion'].notna())\n",
    "]\n",
    "\n",
    "# === 5. è™•ç†å¤šå€‹ emotion çš„æ¬„ä½ ===\n",
    "def extract_emotions(series):\n",
    "    all_emotions = []\n",
    "    for item in series.dropna():\n",
    "        parts = [e.strip().lower() for e in item.split('|') if e.strip().lower() not in invalid_emotions]\n",
    "        all_emotions.extend(parts)\n",
    "    return Counter(all_emotions)\n",
    "\n",
    "# === 6. çµ±è¨ˆæ¯å€‹ entity_group çš„æƒ…ç·’ ===\n",
    "all_rows = []\n",
    "\n",
    "for group in ['individual', 'organization']:\n",
    "    be_series = valid_before[valid_before['entity_group'] == group]['emotion']\n",
    "    af_series = valid_after[valid_after['entity_group'] == group]['emotion']\n",
    "\n",
    "    be_counts = extract_emotions(be_series)\n",
    "    af_counts = extract_emotions(af_series)\n",
    "\n",
    "    all_emotions = sorted(set(be_counts.keys()) | set(af_counts.keys()))\n",
    "    total_be = sum(be_counts.values())\n",
    "    total_af = sum(af_counts.values())\n",
    "\n",
    "    for emotion in all_emotions:\n",
    "        be_n = be_counts.get(emotion, 0)\n",
    "        af_n = af_counts.get(emotion, 0)\n",
    "        row = {\n",
    "            'entity_group': group,\n",
    "            'emotion': emotion,\n",
    "            'Before': be_n,\n",
    "            'After': af_n,\n",
    "            'Total': be_n + af_n,\n",
    "            'Before(%)': round(be_n / total_be * 100, 2) if total_be > 0 else 0,\n",
    "            'After(%)': round(af_n / total_af * 100, 2) if total_af > 0 else 0,\n",
    "        }\n",
    "        all_rows.append(row)\n",
    "\n",
    "# === 7. å»ºç«‹ DataFrame ä¸¦æ’åº ===\n",
    "emotion_comparison_df = pd.DataFrame(all_rows)\n",
    "emotion_comparison_df = emotion_comparison_df.sort_values(by=['entity_group', 'Total'], ascending=[True, False])\n",
    "\n",
    "# === 8. åªå–å‰ 20 å€‹ emotion ===\n",
    "top20_emotion_df = emotion_comparison_df.groupby('entity_group').head(20).reset_index(drop=True)\n",
    "\n",
    "# === 9. é¡¯ç¤ºè¨­å®š ===\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.colheader_justify', 'left')\n",
    "\n",
    "# === 10. é¡¯ç¤ºçµæœ ===\n",
    "print(\"ğŸ“Š å€‹äºº vs çµ„ç¹”çš„ Emotion å‰ 20 å æ•¸é‡èˆ‡ç™¾åˆ†æ¯”æ¯”è¼ƒï¼š\")\n",
    "print(top20_emotion_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483cd0d8-bc58-4f40-8d67-b092897062d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Emotion å‰å¾Œæ¯”è¼ƒè¡¨æ ¼ï¼ˆå«è§€å¯Ÿå€¼ã€æœŸæœ›å€¼ã€å·®ç•°èˆ‡ç¸½æ•¸ï¼‰ï¼š\n",
      "          Before_obs  Before_exp  Before_diff  After_obs  After_exp  After_diff  Total Significant_diff\n",
      "emotion                                                                                                \n",
      "sadness   773         827.75     -54.75        890        835.25     54.75       1663   Yes            \n",
      "anger     788         771.01      16.99        761        777.99    -16.99       1549   Yes            \n",
      "fear      649         621.19      27.81        599        626.81    -27.81       1248   Yes            \n",
      "joy       113         101.04      11.96         90        101.96    -11.96        203   Yes            \n",
      "love       74          78.15      -4.15         83         78.85      4.15        157   Yes            \n",
      "surprise   31          28.87       2.13         27         29.13     -2.13         58   Yes            \n",
      "\n",
      "Chi-square statistic: 14.004101483373983\n",
      "p-value: 0.015583383916842752\n",
      "Degrees of freedom: 5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# === 1. è®€å–è³‡æ–™ ===\n",
    "df = pd.read_csv(\"step4_all_with_date.csv\")\n",
    "\n",
    "# === 2. æ—¥æœŸåˆ‡åˆ† ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "cutoff_date = pd.to_datetime(\"2021-03-16\")\n",
    "df['period'] = df['date'].apply(lambda x: 'before' if x < cutoff_date else 'after')\n",
    "\n",
    "# === 3. æ‹† emotion æ¬„ä½ï¼ˆç”¨ | åˆ†éš”ï¼‰===\n",
    "df_exp = df.assign(\n",
    "    emotion=df['emotion'].str.split(r'\\s*\\|\\s*', regex=True)\n",
    ").explode('emotion')\n",
    "\n",
    "# === 4. å»é™¤ç©ºå€¼èˆ‡ç„¡æ•ˆ emotion ===\n",
    "df_exp['emotion'] = df_exp['emotion'].str.strip().str.lower()\n",
    "invalid_emotions = ['cannot be inferred', 'unknown']\n",
    "df_exp = df_exp[~df_exp['emotion'].isin(invalid_emotions)]\n",
    "df_exp = df_exp.dropna(subset=['emotion'])\n",
    "\n",
    "# === 5. å»é‡ï¼šåŒç¯‡æ–‡ç« ã€åŒä¸€ entityã€åŒä¸€ emotion åªä¿ç•™ä¸€æ¬¡ ===\n",
    "df_unique = df_exp.drop_duplicates(subset=['article_id', 'entity', 'emotion'])\n",
    "\n",
    "# === 6. å»ºç«‹ crosstab ===\n",
    "emotion_table = pd.crosstab(df_unique['emotion'], df_unique['period'])\n",
    "\n",
    "# === 7. å¡æ–¹æª¢å®š ===\n",
    "chi2, p, dof, expected = chi2_contingency(emotion_table)\n",
    "\n",
    "# === 8. æ•´ç†çµæœè¡¨æ ¼ ===\n",
    "expected_df = pd.DataFrame(expected, index=emotion_table.index, columns=emotion_table.columns)\n",
    "diff_df = emotion_table - expected_df\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Before_obs': emotion_table['before'],\n",
    "    'Before_exp': expected_df['before'].round(2),\n",
    "    'Before_diff': diff_df['before'].round(2),\n",
    "    'After_obs': emotion_table['after'],\n",
    "    'After_exp': expected_df['after'].round(2),\n",
    "    'After_diff': diff_df['after'].round(2),\n",
    "})\n",
    "result_df['Total'] = result_df['Before_obs'] + result_df['After_obs']\n",
    "\n",
    "# æ•´é«”æ˜¯å¦é¡¯è‘—ï¼ˆç”¨ç¸½é«”çš„ p-valueï¼‰\n",
    "result_df['Significant_diff'] = 'Yes' if p < 0.05 else 'No'\n",
    "\n",
    "# === 9. æ’åº ===\n",
    "result_df = result_df.sort_values(by='Total', ascending=False)\n",
    "\n",
    "# === 10. é¡¯ç¤ºçµæœ ===\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1200)\n",
    "\n",
    "print(\"ğŸ“Š Emotion å‰å¾Œæ¯”è¼ƒè¡¨æ ¼ï¼ˆå«è§€å¯Ÿå€¼ã€æœŸæœ›å€¼ã€å·®ç•°èˆ‡ç¸½æ•¸ï¼‰ï¼š\")\n",
    "print(result_df)\n",
    "\n",
    "print(\"\\nChi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of freedom:\", dof)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
