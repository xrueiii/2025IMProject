{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Statistic: 2225.80\n",
      "P-value: 0.0\n",
      "                                                  GPT  DeepSeek  \\\n",
      "Anti-Asian hate crimes-physical violence related  312      1292   \n",
      "Anti-Asian hate crimes(general)                   739      2020   \n",
      "Discrimination                                    323      1301   \n",
      "Scapegoat                                         437      1264   \n",
      "China/Chinese virus                               339         1   \n",
      "Systemic racism                                   183       563   \n",
      "Microaggressions                                   29       236   \n",
      "Stereotypes                                        40       191   \n",
      "Kung flu/plague                                    97         0   \n",
      "Xenophobia                                        208       463   \n",
      "\n",
      "                                                  Chi-Square_Contribution  \n",
      "Anti-Asian hate crimes-physical violence related               598.753117  \n",
      "Anti-Asian hate crimes(general)                                594.766582  \n",
      "Discrimination                                                 588.967980  \n",
      "Scapegoat                                                      402.074662  \n",
      "China/Chinese virus                                            336.011765  \n",
      "Systemic racism                                                193.565684  \n",
      "Microaggressions                                               161.694340  \n",
      "Stereotypes                                                     98.705628  \n",
      "Kung flu/plague                                                 97.000000  \n",
      "Xenophobia                                                      96.907601  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:909: UserWarning: unknown class(es) ['\"Commie\"', 'Chinese Exclusion Act', 'Hypervigilance', 'Objectification', 'Page act', 'Racial profiling', 'Racial trauma', 'Retaliation'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "gpt_df = pd.read_csv(\"classification_results_with_race_gpt.csv\", encoding=\"ISO-8859-1\")\n",
    "deepseek_df = pd.read_csv(\"classification_results_with_race_deepseek.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# 補空值避免錯誤\n",
    "gpt_df['concepts'] = gpt_df['concepts'].fillna('')\n",
    "deepseek_df['concepts'] = deepseek_df['concepts'].fillna('')\n",
    "\n",
    "# 定義清理函數：排除含 'or'、亂碼、過長或空的條目\n",
    "def clean_concepts(concept_str):\n",
    "    if pd.isna(concept_str):\n",
    "        return []\n",
    "    split_items = re.split(r';|\\|', concept_str)\n",
    "    return [s.strip() for s in split_items if 'or' not in s and len(s.strip()) > 0 and len(s.strip()) < 100 and not re.search(r'[\\x80-\\xFF]', s)]\n",
    "\n",
    "# 套用清理\n",
    "gpt_df['concepts_clean'] = gpt_df['concepts'].apply(clean_concepts)\n",
    "deepseek_df['concepts_clean'] = deepseek_df['concepts'].apply(clean_concepts)\n",
    "\n",
    "# One-hot encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "gpt_bin = pd.DataFrame(mlb.fit_transform(gpt_df['concepts_clean']), columns=mlb.classes_)\n",
    "deepseek_bin = pd.DataFrame(mlb.transform(deepseek_df['concepts_clean']), columns=mlb.classes_)\n",
    "\n",
    "# 各類別計數\n",
    "gpt_counts = gpt_bin.sum(axis=0)\n",
    "deepseek_counts = deepseek_bin.sum(axis=0)\n",
    "\n",
    "# 卡方檢定表\n",
    "contingency = pd.DataFrame({'GPT': gpt_counts, 'DeepSeek': deepseek_counts})\n",
    "\n",
    "# 執行卡方檢定\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(contingency.T)\n",
    "\n",
    "# 計算每類貢獻度\n",
    "contingency['Chi-Square_Contribution'] = (contingency['GPT'] - contingency['DeepSeek'])**2 / (expected[0] + expected[1])\n",
    "contingency_sorted = contingency.sort_values(by='Chi-Square_Contribution', ascending=False)\n",
    "\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.2f}\")\n",
    "print(f\"P-value: {p_val}\")\n",
    "print(contingency_sorted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b30ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL(GPT || DeepSeek): 1.6101\n",
      "KL(DeepSeek || GPT): 0.2682\n",
      "Symmetric KL (Jensen-Shannon approx): 0.9391\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import rel_entr  # KL divergence helper\n",
    "\n",
    "gpt_dist = gpt_counts + 1e-10  # 加上微小值避免除以零\n",
    "deepseek_dist = deepseek_counts + 1e-10\n",
    "\n",
    "# 正規化為機率分布\n",
    "gpt_probs = gpt_dist / gpt_dist.sum()\n",
    "deepseek_probs = deepseek_dist / deepseek_dist.sum()\n",
    "\n",
    "# KL(P‖Q): GPT 相對於 DeepSeek 的 KL 散度\n",
    "kl_gpt_vs_deepseek = np.sum(rel_entr(gpt_probs, deepseek_probs))\n",
    "\n",
    "# KL(Q‖P): DeepSeek 相對於 GPT 的 KL 散度\n",
    "kl_deepseek_vs_gpt = np.sum(rel_entr(deepseek_probs, gpt_probs))\n",
    "\n",
    "# 平均對稱 KL（optional）\n",
    "js_divergence = 0.5 * (kl_gpt_vs_deepseek + kl_deepseek_vs_gpt)\n",
    "\n",
    "# 輸出結果\n",
    "print(f\"KL(GPT || DeepSeek): {kl_gpt_vs_deepseek:.4f}\")\n",
    "print(f\"KL(DeepSeek || GPT): {kl_deepseek_vs_gpt:.4f}\")\n",
    "print(f\"Symmetric KL (Jensen-Shannon approx): {js_divergence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10133125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT 類別總數： 83\n",
      "DeepSeek 類別總數： 43\n",
      "兩者共同的類別數： 35\n",
      "僅 GPT 有的類別： {'Sexual harassment', 'Environmental policies make people vulnerable', 'Kung flu/plague', 'Racial Injustice/Oppression', 'Victimized', 'Othering', 'Threatening language', 'Maliciously Stigmatizing China in Violation of the Principles of Equality and Non-discrimination', 'Hate crimes (general)', 'Anti-Asian Hate Crimes-Physical Violence Related', 'Racial slurs', 'Domestic violence', 'Demographics', 'Hate crimes', 'Prejudice', 'Community impact', 'Physical violence related', 'Fear', 'Viral racism', 'Psychological effect', 'Racialized attacks', 'Hate crimes-physical violence related', 'Ramen Noodle flu', 'Self-defense', 'Wuhan virus/plague', 'Racial Inequity', 'Physical assaults', 'Gender bias', 'Bias', 'Symbolization', 'Weight bias', 'Anti-Asian Hate Crimes(general)', 'Asian Virus', 'Diversity', 'Gendered bias', 'Hate crimes(general)', 'Immigrant experience', 'Collective action', 'Diseased Chinese', 'Gendered racism', 'Physical Harassment', 'Gaslighting', 'Gender identity issue', 'Hate crime', 'Gendered impacts of disease outbreaks', 'Anti-Asian hate crimes', 'Health care missing when needed', 'Education'}\n",
      "僅 DeepSeek 有的類別： {'Hypervigilance', 'Chinese Exclusion Act', '\"Commie\"', 'Racial profiling', 'Retaliation', 'Objectification', 'Racial trauma', 'Page act'}\n"
     ]
    }
   ],
   "source": [
    "gpt_categories = set([item for sublist in gpt_df['concepts_clean'] for item in sublist])\n",
    "deepseek_categories = set([item for sublist in deepseek_df['concepts_clean'] for item in sublist])\n",
    "\n",
    "print(\"GPT 類別總數：\", len(gpt_categories))\n",
    "print(\"DeepSeek 類別總數：\", len(deepseek_categories))\n",
    "print(\"兩者共同的類別數：\", len(gpt_categories & deepseek_categories))\n",
    "print(\"僅 GPT 有的類別：\", gpt_categories - deepseek_categories)\n",
    "print(\"僅 DeepSeek 有的類別：\", deepseek_categories - gpt_categories)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
