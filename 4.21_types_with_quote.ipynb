{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5a594-e179-4800-b58a-e74ab2296407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:46<00:46, 46.43s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "article_num = 2\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Load your files\n",
    "articles_df = pd.read_csv(\"articles.csv\").head(article_num)\n",
    "definitions_df = pd.read_excel(\"racism_types_definitions.xlsx\")\n",
    "samples_df = pd.read_excel(\"sample_racism_classification.xlsx\").head(150)\n",
    "\n",
    "concept_defs = \"\\n\".join(\n",
    "    f\"{row['concepts']}: {row['definitions'][:300]}\"\n",
    "    for _, row in definitions_df.iterrows()\n",
    ")\n",
    "\n",
    "examples = \"\\n\".join(\n",
    "    f'\"{row[\"annotated_sentence\"]}\" → {row[\"annotation_content\"]}'\n",
    "    for _, row in samples_df.iterrows()\n",
    ")\n",
    "def split_text(text, max_chars=3000):\n",
    "    \"\"\"Splits text into chunks of approximately max_chars, preferably at sentence boundaries.\"\"\"\n",
    "    sentences = text.split('. ')\n",
    "    chunks = []\n",
    "    current_chunk = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) < max_chars:\n",
    "            current_chunk += sentence + '. '\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + '. '\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "# Prompt builder\n",
    "def build_full_article_prompt(article_text, concept_defs, examples):\n",
    "    return f\"\"\"\n",
    "You are a sociology professor with 30 years of experience analyzing the effects and causes of Asian racism.\n",
    "Your task is to identify the quotes in articles that match your list of types of racism concepts.\n",
    "\n",
    "First, read through the racism concept definitions. \n",
    "You need to understand these definitions so you can accurately recognize when a quote fits one or more of these concepts:\n",
    "{concept_defs}\n",
    "\n",
    "Next, review the example labeled quotes provided. \n",
    "You need to study these examples to see how quotes have been matched to concepts in practice, which will guide your own labeling decisions:\n",
    "{examples}\n",
    "\n",
    "Now, read the article below. For each quote that matches a concept, return:\n",
    "- The quote (exact text from article)\n",
    "- The matched concept(s)\n",
    "\n",
    "ARTICLE:\n",
    "{article_text}\n",
    "\n",
    "Return a list of quote/concept pairs in this format:\n",
    "[\n",
    "  {{\"quote\": \"...\", \"concepts\": [\"concept1\", \"concept2\"]}},\n",
    "  ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# Output container\n",
    "all_results = []\n",
    "\n",
    "# Loop through a few articles (start small to avoid token overload)\n",
    "for idx, row in tqdm(articles_df.iterrows(), total=article_num):\n",
    "    article_text = row[\"ARTICLE_TEXT\"]\n",
    "    article_id = row[\"id\"]\n",
    "    title = row[\"title\"]\n",
    "\n",
    "    # Split into chunks\n",
    "    chunks = split_text(article_text)\n",
    "\n",
    "    for chunk_idx, chunk_text in enumerate(chunks):\n",
    "        prompt = build_full_article_prompt(chunk_text, concept_defs, examples)\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a sociology professor analyzing racism in text. Label quotes using provided concepts.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.2\n",
    "            )\n",
    "\n",
    "            output = response.choices[0].message.content\n",
    "\n",
    "            # Parse JSON output\n",
    "            try:\n",
    "                quote_labels = json.loads(output)\n",
    "                for q in quote_labels:\n",
    "                    for concept in q[\"concepts\"]:\n",
    "                        all_results.append({\n",
    "                            \"article_id\": article_id,\n",
    "                            \"title\": title,\n",
    "                            \"quote\": q[\"quote\"],\n",
    "                            \"concept\": concept\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ JSON error for article {article_id} chunk {chunk_idx}: {e}\")\n",
    "                print(\"🔍 Model output:\\n\", output)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ API error for article {article_id} chunk {chunk_idx}: {e}\")\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(\"classification_results.csv\", index=False)\n",
    "print(\"✅ Done! Saved to classification_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
