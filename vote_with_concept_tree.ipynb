{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ead59ab",
   "metadata": {},
   "source": [
    "一般統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Statistic: 2225.80\n",
      "P-value: 0.0\n",
      "                                                  GPT  DeepSeek  \\\n",
      "Anti-Asian hate crimes-physical violence related  312      1292   \n",
      "Anti-Asian hate crimes(general)                   739      2020   \n",
      "Discrimination                                    323      1301   \n",
      "Scapegoat                                         437      1264   \n",
      "China/Chinese virus                               339         1   \n",
      "Systemic racism                                   183       563   \n",
      "Microaggressions                                   29       236   \n",
      "Stereotypes                                        40       191   \n",
      "Kung flu/plague                                    97         0   \n",
      "Xenophobia                                        208       463   \n",
      "\n",
      "                                                  Chi-Square_Contribution  \n",
      "Anti-Asian hate crimes-physical violence related               598.753117  \n",
      "Anti-Asian hate crimes(general)                                594.766582  \n",
      "Discrimination                                                 588.967980  \n",
      "Scapegoat                                                      402.074662  \n",
      "China/Chinese virus                                            336.011765  \n",
      "Systemic racism                                                193.565684  \n",
      "Microaggressions                                               161.694340  \n",
      "Stereotypes                                                     98.705628  \n",
      "Kung flu/plague                                                 97.000000  \n",
      "Xenophobia                                                      96.907601  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:909: UserWarning: unknown class(es) ['\"Commie\"', 'Chinese Exclusion Act', 'Hypervigilance', 'Objectification', 'Page act', 'Racial profiling', 'Racial trauma', 'Retaliation'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "gpt_df = pd.read_csv(\"classification_results_with_race_gpt.csv\", encoding=\"ISO-8859-1\")\n",
    "deepseek_df = pd.read_csv(\"classification_results_with_race_deepseek.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# 補空值避免錯誤\n",
    "gpt_df['concepts'] = gpt_df['concepts'].fillna('')\n",
    "deepseek_df['concepts'] = deepseek_df['concepts'].fillna('')\n",
    "\n",
    "# 定義清理函數：排除含 'or'、亂碼、過長或空的條目\n",
    "def clean_concepts(concept_str):\n",
    "    if pd.isna(concept_str):\n",
    "        return []\n",
    "    split_items = re.split(r';|\\|', concept_str)\n",
    "    return [s.strip() for s in split_items if 'or' not in s and len(s.strip()) > 0 and len(s.strip()) < 100 and not re.search(r'[\\x80-\\xFF]', s)]\n",
    "\n",
    "# 套用清理\n",
    "gpt_df['concepts_clean'] = gpt_df['concepts'].apply(clean_concepts)\n",
    "deepseek_df['concepts_clean'] = deepseek_df['concepts'].apply(clean_concepts)\n",
    "\n",
    "# One-hot encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "gpt_bin = pd.DataFrame(mlb.fit_transform(gpt_df['concepts_clean']), columns=mlb.classes_)\n",
    "deepseek_bin = pd.DataFrame(mlb.transform(deepseek_df['concepts_clean']), columns=mlb.classes_)\n",
    "\n",
    "# 各類別計數\n",
    "gpt_counts = gpt_bin.sum(axis=0)\n",
    "deepseek_counts = deepseek_bin.sum(axis=0)\n",
    "\n",
    "# 卡方檢定表\n",
    "contingency = pd.DataFrame({'GPT': gpt_counts, 'DeepSeek': deepseek_counts})\n",
    "\n",
    "# 執行卡方檢定\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(contingency.T)\n",
    "\n",
    "# 計算每類貢獻度\n",
    "contingency['Chi-Square_Contribution'] = (contingency['GPT'] - contingency['DeepSeek'])**2 / (expected[0] + expected[1])\n",
    "contingency_sorted = contingency.sort_values(by='Chi-Square_Contribution', ascending=False)\n",
    "\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.2f}\")\n",
    "print(f\"P-value: {p_val}\")\n",
    "print(contingency_sorted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b30ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL(GPT || DeepSeek): 1.6101\n",
      "KL(DeepSeek || GPT): 0.2682\n",
      "Symmetric KL (Jensen-Shannon approx): 0.9391\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import rel_entr  # KL divergence helper\n",
    "\n",
    "gpt_dist = gpt_counts + 1e-10  # 加上微小值避免除以零\n",
    "deepseek_dist = deepseek_counts + 1e-10\n",
    "\n",
    "# 正規化為機率分布\n",
    "gpt_probs = gpt_dist / gpt_dist.sum()\n",
    "deepseek_probs = deepseek_dist / deepseek_dist.sum()\n",
    "\n",
    "# KL(P‖Q): GPT 相對於 DeepSeek 的 KL 散度\n",
    "kl_gpt_vs_deepseek = np.sum(rel_entr(gpt_probs, deepseek_probs))\n",
    "\n",
    "# KL(Q‖P): DeepSeek 相對於 GPT 的 KL 散度\n",
    "kl_deepseek_vs_gpt = np.sum(rel_entr(deepseek_probs, gpt_probs))\n",
    "\n",
    "# 平均對稱 KL（optional）\n",
    "js_divergence = 0.5 * (kl_gpt_vs_deepseek + kl_deepseek_vs_gpt)\n",
    "\n",
    "# 輸出結果\n",
    "print(f\"KL(GPT || DeepSeek): {kl_gpt_vs_deepseek:.4f}\")\n",
    "print(f\"KL(DeepSeek || GPT): {kl_deepseek_vs_gpt:.4f}\")\n",
    "print(f\"Symmetric KL (Jensen-Shannon approx): {js_divergence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10133125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT 類別總數： 83\n",
      "DeepSeek 類別總數： 43\n",
      "兩者共同的類別數： 35\n",
      "僅 GPT 有的類別： {'Sexual harassment', 'Environmental policies make people vulnerable', 'Kung flu/plague', 'Racial Injustice/Oppression', 'Victimized', 'Othering', 'Threatening language', 'Maliciously Stigmatizing China in Violation of the Principles of Equality and Non-discrimination', 'Hate crimes (general)', 'Anti-Asian Hate Crimes-Physical Violence Related', 'Racial slurs', 'Domestic violence', 'Demographics', 'Hate crimes', 'Prejudice', 'Community impact', 'Physical violence related', 'Fear', 'Viral racism', 'Psychological effect', 'Racialized attacks', 'Hate crimes-physical violence related', 'Ramen Noodle flu', 'Self-defense', 'Wuhan virus/plague', 'Racial Inequity', 'Physical assaults', 'Gender bias', 'Bias', 'Symbolization', 'Weight bias', 'Anti-Asian Hate Crimes(general)', 'Asian Virus', 'Diversity', 'Gendered bias', 'Hate crimes(general)', 'Immigrant experience', 'Collective action', 'Diseased Chinese', 'Gendered racism', 'Physical Harassment', 'Gaslighting', 'Gender identity issue', 'Hate crime', 'Gendered impacts of disease outbreaks', 'Anti-Asian hate crimes', 'Health care missing when needed', 'Education'}\n",
      "僅 DeepSeek 有的類別： {'Hypervigilance', 'Chinese Exclusion Act', '\"Commie\"', 'Racial profiling', 'Retaliation', 'Objectification', 'Racial trauma', 'Page act'}\n"
     ]
    }
   ],
   "source": [
    "gpt_categories = set([item for sublist in gpt_df['concepts_clean'] for item in sublist])\n",
    "deepseek_categories = set([item for sublist in deepseek_df['concepts_clean'] for item in sublist])\n",
    "\n",
    "print(\"GPT 類別總數：\", len(gpt_categories))\n",
    "print(\"DeepSeek 類別總數：\", len(deepseek_categories))\n",
    "print(\"兩者共同的類別數：\", len(gpt_categories & deepseek_categories))\n",
    "print(\"僅 GPT 有的類別：\", gpt_categories - deepseek_categories)\n",
    "print(\"僅 DeepSeek 有的類別：\", deepseek_categories - gpt_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b0941",
   "metadata": {},
   "source": [
    "確認投票"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffecae0",
   "metadata": {},
   "source": [
    "1. 單純child & parent投票，parent牽涉權重：0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1004e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ 全部流程已定義完畢。請呼叫 `run_voting_pipeline()` 來執行。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === STEP 1: 讀取模型輸出 ===\n",
    "def read_model_outputs(gpt_path, deepseek_path, encoding_list=['utf-8-sig', 'big5', 'latin1']):\n",
    "    for enc in encoding_list:\n",
    "        try:\n",
    "            gpt_df = pd.read_excel(gpt_path)\n",
    "            deepseek_df = pd.read_excel(deepseek_path)\n",
    "            return gpt_df, deepseek_df\n",
    "        except Exception:\n",
    "            continue\n",
    "    raise ValueError(\"All encodings failed for reading files.\")\n",
    "\n",
    "# === STEP 2: 概念清洗與轉集合 ===\n",
    "def process_concepts(concept_str):\n",
    "    if pd.isna(concept_str):\n",
    "        return set()\n",
    "    return set(c.strip().lower() for c in concept_str.split(';') if c.strip())\n",
    "\n",
    "# === STEP 3: 合併資料並投票 ===\n",
    "def vote_concepts(gpt_df, deepseek_df):\n",
    "    gpt_df['concepts'] = gpt_df['concepts'].astype(str)\n",
    "    deepseek_df['concepts'] = deepseek_df['concepts'].astype(str)\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        gpt_df[['quote', 'concepts']].rename(columns={'concepts': 'concepts_gpt'}),\n",
    "        deepseek_df[['quote', 'concepts']].rename(columns={'concepts': 'concepts_deepseek'}),\n",
    "        on='quote',\n",
    "        how='outer'\n",
    "    )\n",
    "\n",
    "    merged_df['concepts_gpt_set'] = merged_df['concepts_gpt'].apply(process_concepts)\n",
    "    merged_df['concepts_deepseek_set'] = merged_df['concepts_deepseek'].apply(process_concepts)\n",
    "\n",
    "    def vote(row):\n",
    "        counts = {}\n",
    "        for c in row['concepts_gpt_set']:\n",
    "            counts[c] = counts.get(c, 0) + 1\n",
    "        for c in row['concepts_deepseek_set']:\n",
    "            counts[c] = counts.get(c, 0) + 1\n",
    "        return counts\n",
    "\n",
    "    merged_df['voted_concepts'] = merged_df.apply(vote, axis=1)\n",
    "    return merged_df\n",
    "\n",
    "# === STEP 4: 引入 Concept Tree 進階分析（選用） ===\n",
    "def flatten_votes_with_tree(voted_dict, concept_tree):\n",
    "    expanded_votes = {}\n",
    "    for concept, count in voted_dict.items():\n",
    "        expanded_votes[concept] = expanded_votes.get(concept, 0) + count\n",
    "\n",
    "        # 允許一對多的 parent list\n",
    "        parents = concept_tree.get(concept.lower(), [])\n",
    "        if isinstance(parents, str):\n",
    "            parents = [parents]\n",
    "        for parent in parents:\n",
    "            expanded_votes[parent] = expanded_votes.get(parent, 0) + count * 0.5  # 可調整權重\n",
    "    return expanded_votes\n",
    "\n",
    "# === STEP 5: 建立完整流程 ===\n",
    "def run_voting_pipeline(gpt_path, deepseek_path, concept_tree={}):\n",
    "    gpt_df, deepseek_df = read_model_outputs(gpt_path, deepseek_path)\n",
    "    merged_df = vote_concepts(gpt_df, deepseek_df)\n",
    "\n",
    "    if concept_tree:\n",
    "        merged_df['voted_with_tree'] = merged_df['voted_concepts'].apply(\n",
    "            lambda vc: flatten_votes_with_tree(vc, concept_tree)\n",
    "        )\n",
    "    return merged_df\n",
    "\n",
    "concept_tree = {\n",
    "    \"white supremacy\": [\"racial injustice/inequity and oppression\"],\n",
    "    \"preserve whiteness\": [\"racial injustice/inequity and oppression\"],\n",
    "    \"white privilege\": [\"racial injustice/inequity and oppression\"],\n",
    "    \"racial bias\": [\"racial injustice/inequity and oppression\"],\n",
    "    \"(domestic) terrorism\": [\"racial injustice/inequity and oppression\"],\n",
    "    '\"china/chinese/asian virus\"/\"kung flu/plague/ramen noodle flu\"': [\"racial injustice/inequity and oppression\"],\n",
    "    \"racial injustice/inequity and oppression\": [\"systematic racism\"],\n",
    "    \"systematic racism\": [\"macro-level racism\"],\n",
    "    \"macro-level racism\": [\"types of anti-asian hate\"],\n",
    "    \"page act (a historical law passed in 1875)\": [\"cultural complexity\"],\n",
    "    \"cultural complexity\": [\"racial injustice/inequity and oppression\"],\n",
    "\n",
    "    # Individual-level racism 分支\n",
    "    \"commie\": [\"bigotry/prejudice\"],\n",
    "    \"yellow peril\": [\"bigotry/prejudice\"],\n",
    "    \"ching chong\": [\"bigotry/prejudice\"],\n",
    "    \"perpetual/forever foreigner (go back to china)\": [\"bigotry/prejudice\"],\n",
    "    \"racism toward asian women\": [\"bigotry/prejudice\"],\n",
    "    \"scapegoat\": [\"bigotry/prejudice\"],\n",
    "    \"misogyny\": [\"scapegoat\"],\n",
    "    \"xenophobia\": [\"scapegoat\"],\n",
    "    \"bigotry/prejudice\": [\"individual level racism\"],\n",
    "    \"individual level racism\": [\"types of anti-asian hate\"],\n",
    "\n",
    "    # Racial discrimination 分支\n",
    "    \"anti-asian hate crimes(general)\": [\"racial discrimination\"],\n",
    "    \"anti-asian hate crimes-physical violence related\": [\"anti-asian hate crimes(general)\"],\n",
    "    \"physical\": [\"harassments\"],\n",
    "    \"verbal\": [\"harassments\"],\n",
    "    \"online\": [\"harassments\"],\n",
    "    \"harassments\": [\"anti-asian hate crimes(general)\"],\n",
    "    \"microaggression\": [\"racial discrimination\"],\n",
    "    \"racial discrimination\": [\"types of anti-asian hate\"],\n",
    "\n",
    "    # 歧視來源類型\n",
    "    \"other minorities (e.g., black) attack aa\": [\"anti-asian hate crimes-physical violence related\"],\n",
    "    \"attacked by white or not specified\": [\"anti-asian hate crimes-physical violence related\"],\n",
    "    \"recidivism\": [\"anti-asian hate crimes-physical violence related\", \"harassments\"],\n",
    "    \"sexual violence\": [\"anti-asian hate crimes-physical violence related\"]\n",
    "}\n",
    "\n",
    "# === 執行主程式（記得替換自己的） ===\n",
    "final_df = run_voting_pipeline(\"classification_test_gpt.xlsx\", \"classification_test_deepseek.xlsx\", concept_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cc576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ 已成功輸出至 concept_voting_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "final_df# === STEP 6: 將結果輸出為 Excel ===\n",
    "def save_to_excel(df, output_path=\"voting_results.xlsx\"):\n",
    "    # 將字典欄位轉為字串，以便寫入 Excel\n",
    "    df_to_save = df.copy()\n",
    "    if 'voted_concepts' in df_to_save.columns:\n",
    "        df_to_save['voted_concepts'] = df_to_save['voted_concepts'].apply(lambda d: str(d))\n",
    "    if 'voted_with_tree' in df_to_save.columns:\n",
    "        df_to_save['voted_with_tree'] = df_to_save['voted_with_tree'].apply(lambda d: str(d))\n",
    "\n",
    "    df_to_save.to_excel(output_path, index=False)\n",
    "    print(f\"✔️ 已成功輸出至 {output_path}\")\n",
    "\n",
    "save_to_excel(final_df, \"concept_voting_output.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483e9f0",
   "metadata": {},
   "source": [
    "2. 遞迴concept tree投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f25f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === STEP 1: 讀取模型輸出 ===\n",
    "def read_model_outputs(gpt_path, deepseek_path, encoding_list=['utf-8-sig', 'big5', 'latin1']):\n",
    "    for enc in encoding_list:\n",
    "        try:\n",
    "            gpt_df = pd.read_excel(gpt_path)\n",
    "            deepseek_df = pd.read_excel(deepseek_path)\n",
    "            return gpt_df, deepseek_df\n",
    "        except Exception:\n",
    "            continue\n",
    "    raise ValueError(\"All encodings failed for reading files.\")\n",
    "\n",
    "# === STEP 2: 概念清洗與轉集合 ===\n",
    "def process_concepts(concept_str):\n",
    "    if pd.isna(concept_str):\n",
    "        return set()\n",
    "    return set(c.strip().lower() for c in concept_str.split(';') if c.strip())\n",
    "\n",
    "# === STEP 3: 合併資料並投票 ===\n",
    "def vote_concepts(gpt_df, deepseek_df):\n",
    "    gpt_df['concepts'] = gpt_df['concepts'].astype(str)\n",
    "    deepseek_df['concepts'] = deepseek_df['concepts'].astype(str)\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        gpt_df[['quote', 'concepts']].rename(columns={'concepts': 'concepts_gpt'}),\n",
    "        deepseek_df[['quote', 'concepts']].rename(columns={'concepts': 'concepts_deepseek'}),\n",
    "        on='quote',\n",
    "        how='outer'\n",
    "    )\n",
    "\n",
    "    merged_df['concepts_gpt_set'] = merged_df['concepts_gpt'].apply(process_concepts)\n",
    "    merged_df['concepts_deepseek_set'] = merged_df['concepts_deepseek'].apply(process_concepts)\n",
    "\n",
    "    def vote(row):\n",
    "        counts = {}\n",
    "        for c in row['concepts_gpt_set']:\n",
    "            counts[c] = counts.get(c, 0) + 1\n",
    "        for c in row['concepts_deepseek_set']:\n",
    "            counts[c] = counts.get(c, 0) + 1\n",
    "        return counts\n",
    "\n",
    "    merged_df['voted_concepts'] = merged_df.apply(vote, axis=1)\n",
    "    return merged_df\n",
    "\n",
    "# === STEP 4: 引入 Concept Tree 進階分析（選用） ===\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "def flatten_votes_with_tree(voted_dict, concept_tree):\n",
    "    expanded_votes = defaultdict(float)\n",
    "\n",
    "    def add_with_ancestors(concept, vote):\n",
    "        queue = deque([(concept, vote)])\n",
    "        visited = set()\n",
    "        while queue:\n",
    "            node, current_vote = queue.popleft()\n",
    "            if node in visited:\n",
    "                continue\n",
    "            visited.add(node)\n",
    "            expanded_votes[node] += current_vote\n",
    "\n",
    "            # 找到父節點\n",
    "            parents = concept_tree.get(node.lower(), [])\n",
    "            if isinstance(parents, str):\n",
    "                parents = [parents]\n",
    "            for parent in parents:\n",
    "                queue.append((parent, current_vote * 0.5))  # 向上傳遞時的權重（可調）\n",
    "\n",
    "    # 對每個投票概念啟動遞迴傳票\n",
    "    for concept, count in voted_dict.items():\n",
    "        add_with_ancestors(concept, count)\n",
    "\n",
    "    return dict(expanded_votes)\n",
    "\n",
    "# === STEP 5: 建立完整流程 ===\n",
    "def run_voting_pipeline(gpt_path, deepseek_path, concept_tree={}):\n",
    "    gpt_df, deepseek_df = read_model_outputs(gpt_path, deepseek_path)\n",
    "    merged_df = vote_concepts(gpt_df, deepseek_df)\n",
    "\n",
    "    if concept_tree:\n",
    "        merged_df['voted_with_tree'] = merged_df['voted_concepts'].apply(\n",
    "            lambda vc: flatten_votes_with_tree(vc, concept_tree)\n",
    "        )\n",
    "    return merged_df\n",
    "\n",
    "concept_tree = {\n",
    "    # Macro-level racism 分支\n",
    "    \"white supremacy\": [\"racial injustice/inequity and oppression\"],\n",
    "    \"preserve whiteness\": [\"racial injustice/inequity and oppression\"],\n",
    "    \"white privilege\": [\"racial injustice/inequity and oppression\"],\n",
    "    \"racial bias\": [\"racial injustice/inequity and oppression\"],\n",
    "    \"(domestic) terrorism\": [\"racial injustice/inequity and oppression\"],\n",
    "    '\"china/chinese/asian virus\"/\"kung flu/plague/ramen noodle flu\"': [\"racial injustice/inequity and oppression\"],\n",
    "    \"racial injustice/inequity and oppression\": [\"systematic racism\"],\n",
    "    \"systematic racism\": [\"macro-level racism\"],\n",
    "    \"macro-level racism\": [\"types of anti-asian hate\"],\n",
    "    \"page act (a historical law passed in 1875)\": [\"cultural complexity\"],\n",
    "    \"cultural complexity\": [\"racial injustice/inequity and oppression\"],\n",
    "\n",
    "    # Individual-level racism 分支\n",
    "    \"commie\": [\"bigotry/prejudice\"],\n",
    "    \"yellow peril\": [\"bigotry/prejudice\"],\n",
    "    \"ching chong\": [\"bigotry/prejudice\"],\n",
    "    \"perpetual/forever foreigner (go back to china)\": [\"bigotry/prejudice\"],\n",
    "    \"racism toward asian women\": [\"bigotry/prejudice\"],\n",
    "    \"scapegoat\": [\"bigotry/prejudice\"],\n",
    "    \"misogyny\": [\"scapegoat\"],\n",
    "    \"xenophobia\": [\"scapegoat\"],\n",
    "    \"bigotry/prejudice\": [\"individual level racism\"],\n",
    "    \"individual level racism\": [\"types of anti-asian hate\"],\n",
    "\n",
    "    # Racial discrimination 分支\n",
    "    \"anti-asian hate crimes(general)\": [\"racial discrimination\"],\n",
    "    \"anti-asian hate crimes-physical violence related\": [\"anti-asian hate crimes(general)\"],\n",
    "    \"physical\": [\"harassments\"],\n",
    "    \"verbal\": [\"harassments\"],\n",
    "    \"online\": [\"harassments\"],\n",
    "    \"harassments\": [\"anti-asian hate crimes(general)\"],\n",
    "    \"microaggression\": [\"racial discrimination\"],\n",
    "    \"racial discrimination\": [\"types of anti-asian hate\"],\n",
    "\n",
    "    # 歧視來源類型\n",
    "    \"other minorities (e.g., black) attack aa\": [\"anti-asian hate crimes-physical violence related\"],\n",
    "    \"attacked by white or not specified\": [\"anti-asian hate crimes-physical violence related\"],\n",
    "    \"recidivism\": [\"anti-asian hate crimes-physical violence related\", \"harassments\"],\n",
    "    \"sexual violence\": [\"anti-asian hate crimes-physical violence related\"]\n",
    "}\n",
    "\n",
    "# === 執行主程式（記得替換自己的） ===\n",
    "final_df_2 = run_voting_pipeline(\"classification_test_gpt.xlsx\", \"classification_test_deepseek.xlsx\", concept_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c75a6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ 已成功輸出至 concept_voting_output_2.xlsx\n"
     ]
    }
   ],
   "source": [
    "final_df_2\n",
    "# === STEP 6: 將結果輸出為 Excel ===\n",
    "def save_to_excel(df, output_path=\"voting_results.xlsx\"):\n",
    "    # 將字典欄位轉為字串，以便寫入 Excel\n",
    "    df_to_save = df.copy()\n",
    "    if 'voted_concepts' in df_to_save.columns:\n",
    "        df_to_save['voted_concepts'] = df_to_save['voted_concepts'].apply(lambda d: str(d))\n",
    "    if 'voted_with_tree' in df_to_save.columns:\n",
    "        df_to_save['voted_with_tree'] = df_to_save['voted_with_tree'].apply(lambda d: str(d))\n",
    "\n",
    "    df_to_save.to_excel(output_path, index=False)\n",
    "    print(f\"✔️ 已成功輸出至 {output_path}\")\n",
    "\n",
    "save_to_excel(final_df_2, \"concept_voting_output_2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159460da",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_tree = {\n",
    "    \"systematic racism\": [\"Macro-level racism\"],\n",
    "    \"racial injustice/inequity and oppression\": [\"systematic racism\"],\n",
    "    \"white supremacy\": [\"systematic racism\"],\n",
    "    \"preserve whiteness\": [\"systematic racism\"],\n",
    "    \"white privilege\": [\"systematic racism\"],\n",
    "    \"Racial bias\": [\"systematic racism\"],\n",
    "    \"(Domestic) terrorism\": [\"systematic racism\"],\n",
    "    \n",
    "    \n",
    "    \"Bigotry/prejudice\": [\"Individual-level racism\"],\n",
    "    \"“China/Chinese/Asian virus”/“Kung flu/plague/Ramen noodle flu”\": [\"Bigotry/prejudice\"],\n",
    "    \"commie\": [\"Bigotry/prejudice\"],\n",
    "    \"yellow peril\": [\"Bigotry/prejudice\"],\n",
    "    \"Ching Chong\": [\"Bigotry/prejudice\"],\n",
    "    \"Perpetual/forever foreinger (Go back to China)\": [\"Bigotry/prejudice\"],\n",
    "    \"Scapegoat\": [\"Bigotry/prejudice\"],\n",
    "    \n",
    "    \n",
    "    \"Racial discrimination\": [\"Individual-level racism\"],\n",
    "    \"Anti-Asian hate crimes(general)\": [\"Racial discrimination\"],\n",
    "    \"Microaggression\": [\"Racial discrimination\"],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b036f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
